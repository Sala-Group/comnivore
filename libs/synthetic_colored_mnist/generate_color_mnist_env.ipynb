{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Grayscale(num_output_channels=3)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")\n",
      "==============================\n",
      "Train data set: 54000\n",
      "Test data set: 10000\n",
      "Valid data set: 6000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mnist_tasks.generate_color_mnist import *\n",
    "from mnist_tasks.mnist_loader import trainloader, testloader, valloader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import pandas as pd\n",
    "    \n",
    "transform = {\n",
    "    \"background\": transform_digit_color,\n",
    "    \"full\": transform_image\n",
    "}\n",
    "random_generator = {\n",
    "    \"background\": generate_random_digit_color,\n",
    "    \"full\": generate_random_environment\n",
    "}\n",
    "#change the const below to change generator\n",
    "MODE = \"background\"\n",
    "\n",
    "#digits to store\n",
    "digits_to_store = [0, 1]\n",
    "\n",
    "store_dir = \"/hdd2/dyah/coloredmnist_synthetic\"\n",
    "if not os.path.isdir(store_dir):\n",
    "    os.makedirs(store_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing environment generation mode\n",
    "\"background\" mode is just changing the background color, digit color will stay white <br>\n",
    "\"full\" is changing both digit and background color <br>\n",
    "change the constant in \"MODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image_with_env(env, loader):\n",
    "    images = torch.zeros((1,3,28,28))\n",
    "    y_true = []\n",
    "    for batch_idx, (imgs, labels) in tqdm(enumerate(loader)):\n",
    "        if len(digits_to_store) > 0:\n",
    "            mask = np.logical_or(labels == digits_to_store[0], labels == digits_to_store[1])\n",
    "            imgs = imgs[mask,:,:,:]\n",
    "            labels = labels[mask]\n",
    "        transformed_imgs = transform[MODE](imgs, labels,env)\n",
    "        images=torch.vstack((images,transformed_imgs))\n",
    "        y_true.extend(labels.detach().cpu().numpy())\n",
    "    images = images[1:,:,:,:]\n",
    "    y_true = torch.Tensor(y_true)\n",
    "    return images, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_flip_map(digits=digits_to_store):\n",
    "    if len(digits) == 0:\n",
    "        digits = np.arange(10)\n",
    "    random_shuffle = np.copy(digits)\n",
    "    np.random.shuffle(random_shuffle)\n",
    "    random_mapping = {}\n",
    "    for idx, digit in enumerate(digits):\n",
    "        random_mapping[digit] = random_shuffle[idx]\n",
    "    return random_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_digit_color(flip_mapping, env):\n",
    "    new_mapping = {}\n",
    "    for key in flip_mapping:\n",
    "        new_mapping[key] = env[flip_mapping[key]]\n",
    "        new_mapping[flip_mapping[key]] = env[key]\n",
    "    return new_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_images(images):\n",
    "    random_samples = np.random.choice(np.linspace(0, images.shape[0]-1, images.shape[0], dtype=int), 10)\n",
    "    random_samples = images[random_samples, :,:,:]\n",
    "    nrows = 3\n",
    "    fig, ax = plt.subplots(nrows, ncols=random_samples.shape[0]//nrows)\n",
    "    i=0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            image = random_samples[i,:,:,:]*255\n",
    "            col.imshow(image.permute(1,2,0).detach().cpu().numpy().astype(np.uint8))\n",
    "            i+=1\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_and_get_metadata(images, labels, split, save_dir):\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    image_id = 0\n",
    "    transform = T.ToPILImage()\n",
    "    metadata_df = {\"image_path\": [], \"label\": [], \"split\": []}\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    for img_idx in range(images.shape[0]):\n",
    "        img_tensor = images[img_idx, :, :, :]\n",
    "        img_tensor = torch.squeeze(img_tensor)\n",
    "        image_id += 1\n",
    "        img = transform(img_tensor)\n",
    "        image_path = os.path.join(save_dir, f\"img_{image_id}_{split}.png\")\n",
    "        img.save(image_path)\n",
    "        metadata_df[\"image_path\"].append(image_path)\n",
    "        metadata_df[\"label\"].append(int(labels[img_idx]))\n",
    "        metadata_df[\"split\"].append(split)\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.4627451 , 0.29803922, 0.61176471]),\n",
       " 1: array([0.70980392, 0.49411765, 0.42352941])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_1 = random_generator[MODE](digits_to_store)\n",
    "env_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  import sys\n",
      "/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  \n",
      "422it [03:13,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "img_env_1_train, env_1_labels_train = transform_image_with_env(env_1, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAGMCAYAAADky7rwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADfdJREFUeJzt3cFqG1cbBuAj48YkoBsQ0tV0F+g1tNBNN4Gu2mXIsl0Vsumm0F5DIbtejYxuQJDgEDT/oqh2RX8rx6PRvEfzPLtQj3Wwvur1mddHmnVd1xUAYHRXYy8AAPibUAaAEEIZAEIIZQAIIZQBIIRQBoAQQhkAQghlAAghlAEghFAGgBBCGQBCXNdesNvtymazKfP5vMxmsyHWxIl1XVe2221ZLBbl6mrav4eZ37aY3Xtmty1Pnd3qUN5sNmW1WtVeRoD1el2Wy+XYyxiV+W2T2TW7raqd3epQns/npZRSvvvy53Jz/bz2ckZw9+lD+fWvH/557qZs/zP44/tvyoubZyOvhmPe330sX//yu9ktXntb89TX3epQ3t82ubl+Xm6+MBgtccvr/mfw4uaZUG6I2fXa26ra2Z12SQMAQYQyAIQQygAQQigDQAihDAAhhDIAhBDKABBCKANACKEMACGEMgCEEMoAEEIoA0AIoQwAIao/JQrI9PLN20f/+7vXr860Eijlpz+/ffK1P3712wlX0hY7ZQAIIZQBIITb19CwY7esoUXHbn1f8u1tO2UACCGUASCEUAaAEDplmIjD/tkRKfroc+Rp6MduuXO2UwaAEEIZAEIIZQAIoVMG4Owe9r6n7qdb7pztlAEghFAGgBBCGQBCNN8pH3YHyV0BwFQ99trc93V7zDPTp2anDAAhhDIAhBDKABAirlPu2w30uV4fDcCY7JQBIIRQBoAQQhkAQsR1ymNy5hngv13SWeBkdsoAEEIoA0AIoQwAIZrvlId8z9SxP5Pz4ePrt4GWeM16GjtlAAghlAEghFAGgBDNdcqn7ike+37HOuVznmt2hppSSnn55u3YSwAGZKcMACGEMgCEEMoAEKK5TvmcjvW2hz3vqXvfh9cP/VgAjzl8jfFe2MOwUwaAEEIZAEK4fd3D0Ldz3B7ilN69fjX2EmiY16PzsFMGgBBCGQBCCGUACBHXKR/raZOPAg35MZIA/O2SXyvtlAEghFAGgBBCGQBCxHXKtU7ZMR/rKWq/95C9R1KXDsBp2CkDQAihDAAhhDIAhIjvlGvfX3rIHvfcZ+P0xkCKvq/FXs8+j50yAIQQygAQQigDQIj4TvnQsV4i6T1RdSjApRr68+Snyk4ZAEIIZQAIIZQBIERznfIxelyAPH3OLfftq1vKBTtlAAghlAEghFAGgBAX1ykD/+3lm7f/+ve7169GWgmX6JSfU9BSB3xqdsoAEEIoA0AIoQwAIXTK0JDDHviwJ4YUfd4be8rvo22nDAAhhDIAhBDKABBCpwzA4Hz+8uexUwaAEEIZAEIIZQAIoVOGhj08t3zszLL3uibJY+9vPaXPTz5kpwwAIYQyAIRw+xouhNvTXIqWbz/3ZacMACGEMgCEEMoAEEIoA0AIoQwAIYQyAIQQygAQQigDQAihDAAhhDIAhBDKABBCKANACKEMACGEMgCEqP7oxq7rSiml3H36cPLFMIz9c7V/7qZs/zN4f/dx5JXwOfbPk9n12tuap77uzrrKK25vb8tqtap6EDKs1+uyXC7HXsaozG+bzK7ZbVXt7FaH8m63K5vNpszn8zKbzaoXyPl1XVe2221ZLBbl6mrajYX5bYvZvWd22/LU2a0OZQBgGNP+1RMAgghlAAghlAEghFAGgBBCGQBCCGUACCGUASCEUAaAEEIZAEIIZQAIIZQBIIRQBoAQQhkAQghlAAghlAEghFAGgBBCGQBCXNdesNvtymazKfP5vMxmsyHWxIl1XVe2221ZLBbl6mrav4eZ37aY3Xtmty1Pnd3qUN5sNmW1WtVeRoD1el2Wy+XYyxiV+W2T2TW7raqd3epQns/npZRS/vj+m/Li5lnt5Yzg/d3H8vUvv//z3E3Z/mfw3Zc/l5vr5yOvhmPuPn0ov/71g9ktZrc1T53d6lDe3zZ5cfNMKDfGLa/7n8HN9fNy84UXtlaYXbPbqtrZnXZJAwBBhDIAhBDKABBCKANACKEMACGEMgCEEMoAEEIoA0AIoQwAIYQyAIQQygAQQigDQAihDAAhqj8l6pK9fPP2X/9+9/rVSCsBYIrslAEghFAGgBBuXz/C7Wxa9tOf31Z9/Y9f/TbQSoDPZacMACGEMgCEEMoAEEKnDBeitkM+dr2OmVb0nf1DY86+nTIAhBDKABBCKANACJ0yNKymSzvsyU7dw0EN8/ff7JQBIIRQBoAQQhkAQuiUoSF9OuS+j+XcMn201CE/XOu5595OGQBCCGUACCGUASCETrmCz1cmmc6XJEN2yKf+e4marx36/zM7ZQAIIZQBIIRQBoAQOmUIds5erqVzpOQ55fwM3dsmz76dMgCEEMoAEEIoA0AInXIF55IZWp9uq/Za55rpo6UOuSV2ygAQQigDQAihDAAhdMowET5fmT5OfZZ3zPlJOpd8yE4ZAEIIZQAIIZQBIIROGS7Eud8vmMt2SR1yH+det50yAIQQygAQYvK3r1++eft//5u31QR4mpaPPI25djtlAAghlAEghFAGgBCT75ShZa0eM2F8jjxlslMGgBBCGQBCCGUACDG5Tvmxc8mQ7pS9XfLH15Gv5XPIh5L6cDtlAAghlAEghFAGgBCT65QByDb03zskdciH7JQBIIRQBoAQQhkAQuiUYUTHurMxu6/k3o3xOec+DDtlAAghlAEghFAGgBA6ZZgIHSBT0fLfQ9gpA0AIoQwAIYQyAITQKT/w7vWrsZcAo2m5h2NaLnlW7ZQBIIRQBoAQQhkAQlx8p/zyzdsnf62OmaEddmOHZ4kP/13TpTmXzGMuuZdtmZ0yAIQQygAQQigDQIiL75QPe+HHOmYdMi2r7ZB1ipDHThkAQghlAAghlAEgxMV3ytCS2nPLfb43kMdOGQBCCGUACDG529eOPdGSY7eza64F8tkpA0AIoQwAIYQyAISYXKcMLdMTw2WzUwaAEEIZAEIIZQAIIZQBIIRQBoAQQhkAQghlAAghlAEghFAGgBBCGQBCVL/NZtd1pZRS3t99PPliGMb+udo/d1O2/xncffow8kr4HPvnyeya3dY8dXZnXeUVt7e3ZbVaVT0IGdbrdVkul2MvY1Tmt01m1+y2qnZ2q0N5t9uVzWZT5vN5mc1m1Qvk/LquK9vttiwWi3J1Ne3Gwvy2xezeM7tteersVocyADCMaf/qCQBBhDIAhBDKABBCKANACKEMACGEMgCEEMoAEEIoA0AIoQwAIYQyAIQQygAQQigDQAihDAAhhDIAhBDKABBCKANACKEMACGEMgCEuK69YLfblc1mU+bzeZnNZkOsiRPruq5st9uyWCzK1dW0fw8zv20xu/fMblueOrvVobzZbMpqtaq9jADr9bosl8uxlzEq89sms2t2W1U7u9WhPJ/PSyml/PH9N+XFzbPayxnB+7uP5etffv/nuZsy89sWs3tv/zP47sufy83185FXwzF3nz6UX//6oXp2q0N5f9vkxc0zL2qNccvL/LbK7N7/DG6un5ebL4RyK2pnd9olDQAEEcoAEEIoA0AIoQwAIYQyAIQQygAQQigDQAihDAAhhDIAhBDKABBCKANACKEMACGEMgCEqP6UKO69fPP20f/+7vWrM60E+jPPpPjpz2+rvv7Hr34baCXnZ6cMACGEMgCEcPu6wrHbe8e+3u0/ktTOM5xS7S3qmu/V8u1sO2UACCGUASCEUAaAEDrlR+jcmDJ/A8EpnbJDrn2sljpmO2UACCGUASCEUAaAEDplmAh/I8E5nbNDPubYWpI6ZztlAAghlAEghFAGgBA65QE550lLzCt9nLJDPtbxnrqvTjrXbKcMACGEMgCEEMoAEEKn/IBznFySY/OsQ6aPljvkYx4+3rn7ZTtlAAghlAEghFAGgBA65QcOO7bajllHB1yqvr1un2728Nqk99U+NTtlAAghlAEghFAGgBA65QecU6Zl5pdTGrNDnjI7ZQAIIZQBIIRQBoAQk++U9XC0rGZ+naOHfHbKABBCKANACKEMACEm3yn3oaMDLoVzyRnslAEghFAGgBBuX8OFUq/wmJZuV1/yRzUeslMGgBBCGQBCCGUACKFThoZ4W1im4NR9d0udtJ0yAIQQygAQQigDQIjJdco6OYB6fc8lP9br9v3el/QWn3bKABBCKANACKEMACEm1yn34b2EObeav4Ewnxwz5nndmt53yP76HI/fh50yAIQQygAQQigDQIiL75T7nEvW0QHka7lDPmSnDAAhhDIAhBDKABDi4jtlANp26vPVSR3yITtlAAghlAEghFAGgBAX1yn7vGSmxFl6zqW21z3sbVt53+2x2SkDQAihDAAhhDIAhLi4TrkP/Rxj8zcRDOlhtzp0x6tDfho7ZQAIIZQBIIRQBoAQOmUAmtZyh3zIThkAQghlAAghlAEgxOQ7ZWeTaYl55VSO9bDOGY/DThkAQghlAAhxcbev3d6jZeaXFFO+hTwmO2UACCGUASCEUAaAEEIZAEIIZQAIIZQBIIRQBoAQQhkAQghlAAghlAEghFAGgBBCGQBCCGUACCGUASBE9Uc3dl1XSinl/d3Hky+GYeyfq/1zN2Xmty1m997+Z3D36cPIK+Fz7J+n2tmddZVX3N7eltVqVfUgZFiv12W5XI69jFGZ3zaZXbPbqtrZrQ7l3W5XNptNmc/nZTabVS+Q8+u6rmy327JYLMrV1bQbC/PbFrN7z+y25amzWx3KAMAwpv2rJwAEEcoAEEIoA0AIoQwAIYQyAIQQygAQQigDQAihDAAhhDIAhBDKABDif60o6/VV9wt0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_images(img_env_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = save_images_and_get_metadata(img_env_1_train, env_1_labels_train, 0, save_dir=os.path.join(store_dir, \"env_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  import sys\n",
      "/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  \n",
      "79it [00:35,  2.24it/s]\n",
      "47it [00:20,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "img_env_1_test, env_1_labels_test = transform_image_with_env(env_1, testloader)\n",
    "test_metadata = save_images_and_get_metadata(img_env_1_test, env_1_labels_test, 1, save_dir=os.path.join(store_dir, \"env_1\"))\n",
    "img_env_1_val, env_1_labels_val = transform_image_with_env(env_1, valloader)\n",
    "val_metadata = save_images_and_get_metadata(img_env_1_val, env_1_labels_val, 2, save_dir=os.path.join(store_dir, \"env_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metadata(train_metadata, test_metadata, val_metadata):\n",
    "    image_path = [path for path in train_metadata['image_path']]\n",
    "    image_path.extend([path for path in test_metadata['image_path']])\n",
    "    image_path.extend([path for path in val_metadata['image_path']])\n",
    "    metadata_all = {'image_path': image_path}\n",
    "    \n",
    "    labels = [label for label in train_metadata['label']]\n",
    "    labels.extend([label for label in test_metadata['label']])\n",
    "    labels.extend([label for label in val_metadata['label']])\n",
    "    metadata_all['label'] = labels\n",
    "    \n",
    "    splits = [split for split in train_metadata['split']]\n",
    "    splits.extend([split for split in test_metadata['split']])\n",
    "    splits.extend([split for split in val_metadata['split']])\n",
    "    metadata_all['split'] = splits\n",
    "    return metadata_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metadata(df, save_dir):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.to_csv(os.path.join(save_dir,\"metadata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_all = merge_metadata(train_metadata, test_metadata, val_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_metadata(metadata_all, save_dir=os.path.join(store_dir, \"env_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_map = generate_random_flip_map()\n",
    "flip_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.70980392, 0.49411765, 0.42352941]),\n",
       " 1: array([0.4627451 , 0.29803922, 0.61176471])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_1_flip = flip_digit_color(flip_map, env_1)\n",
    "env_1_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  import sys\n",
      "/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  \n",
      "422it [03:13,  2.18it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_env_1_train_flip, env_1_labels_train_flip = transform_image_with_env(env_1_flip, trainloader)\n",
    "show_random_images(img_env_1_train_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  import sys\n",
      "/hdd2/dyah/anaconda3/envs/causal/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  \n",
      "3it [00:01,  1.85it/s]"
     ]
    }
   ],
   "source": [
    "train_metadata = save_images_and_get_metadata(img_env_1_train_flip, env_1_labels_train_flip, 0, save_dir=os.path.join(store_dir, \"env_1_FLIP\"))\n",
    "\n",
    "img_env_1_test_flip, env_1_labels_test_flip = transform_image_with_env(env_1_flip, testloader)\n",
    "test_metadata = save_images_and_get_metadata(img_env_1_test_flip, env_1_labels_test_flip, 1, save_dir=os.path.join(store_dir, \"env_1_FLIP\"))\n",
    "\n",
    "img_env_1_val_flip, env_1_labels_val_flip = transform_image_with_env(env_1_flip, valloader)\n",
    "val_metadata = save_images_and_get_metadata(img_env_1_val_flip, env_1_labels_val_flip, 1, save_dir=os.path.join(store_dir, \"env_1_FLIP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_all = merge_metadata(train_metadata, test_metadata, val_metadata)\n",
    "store_metadata(metadata_all, save_dir=os.path.join(store_dir, \"env_1_FLIP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
